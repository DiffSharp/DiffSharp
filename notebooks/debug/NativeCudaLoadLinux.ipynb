{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of 00_notebook_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PEXeK1lbUvvI",
        "Xuz9GCDoUvvS",
        "w6poJ2d7Uvva",
        "JXkraHEyUvvb",
        "4AknCJ3ZUvvj",
        "s5ryOAAYUvvk",
        "1_AcJ1aFUvvm",
        "O8Y-LL6pUvvo",
        "-iXe4caCUvvr",
        "lj350yzxUvv1",
        "woHOQxL5Uvv4",
        "RXkMS_7XUvv6",
        "HbldGT-bUvv7",
        "r2A0LypIUvwB",
        "oRhQ2ZaGUvwM"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiffSharp/DiffSharp/blob/dev/notebooks/debug/NativeCudaLoadLinux.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhwrF74AUvvB"
      },
      "source": [
        "**Important note:** You should always work on a duplicate of the course notebook. On the page you used to open this, tick the box next to the name of the notebook and click duplicate to easily create a new version of this notebook.\n",
        "\n",
        "You will get errors each time you try to update your course repository if you don't do this, and your changes will end up being erased by the original course version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvJXpKRtdFP2"
      },
      "source": [
        "!pip install difftorch\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "\n",
        "import difftorch\n",
        "\n",
        "torch.tensor(True).dtype # uint8\n",
        "#torch.tensor(1).dtype # int64\n",
        "#torch.tensor(True, dtype=torch.bool).dtype # int64\n",
        "#torch.version\n",
        "torch.rand(3, dtype=torch.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZTYwiNhbVQC"
      },
      "source": [
        "import torch\n",
        "torch.max_pool3d(torch.ones([4,4,4,4], dtype=torch.float), [3,3,3])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3YR9deFbcgG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yI0ti8SgCX6"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4Gq57JVKqW5"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "revx = torch.tensor([[[[[ 0.4633,  0.9173,  0.4568, -1.7660, -0.1077],\n",
        "                                         [-2.1112,  1.5542,  0.5720, -1.0952, -1.8144],\n",
        "                                         [ 0.3505, -0.9843, -2.5655, -0.9835,  1.2303],\n",
        "                                         [ 0.8156,  1.5415,  1.3066, -1.1820,  0.2060],\n",
        "                                         [ 0.0684,  1.5936,  0.2956, -0.5176, -1.6960]],\n",
        "\n",
        "                                        [[-1.7281, -0.7697, -2.2310,  0.3580,  0.6299],\n",
        "                                         [ 0.8558, -0.6180, -1.6077, -0.6779,  1.2910],\n",
        "                                         [ 0.1885, -0.7006, -0.1863, -1.6729, -0.5761],\n",
        "                                         [ 0.1940, -0.0399,  0.9329,  1.0687,  0.0955],\n",
        "                                         [-1.0189,  0.4046,  1.1762,  0.3842,  0.6831]],\n",
        "\n",
        "                                        [[ 0.2996,  0.5738,  0.0369,  0.2835, -0.2363],\n",
        "                                         [ 0.6847, -0.4949, -0.3974,  0.6808, -1.2942],\n",
        "                                         [ 1.0910, -0.0594, -0.0037, -0.3355, -1.5056],\n",
        "                                         [-0.0965,  1.1358,  1.2851, -1.7333, -1.1705],\n",
        "                                         [ 0.0966, -1.2780,  1.2939,  1.3469, -0.2603]],\n",
        "\n",
        "                                        [[-0.5270,  1.1442,  0.1259, -1.2813,  0.3536],\n",
        "                                         [ 0.1579,  0.0828,  1.3531, -0.9110, -0.8747],\n",
        "                                         [ 0.2473, -0.1507, -0.4880,  0.4575,  1.1186],\n",
        "                                         [ 2.0900,  1.0479, -0.7209, -1.6928,  1.8761],\n",
        "                                         [ 2.2015, -0.5097,  0.7364, -1.5177,  0.9212]],\n",
        "\n",
        "                                        [[ 1.0358,  1.6584, -1.9654, -1.3971,  1.5641],\n",
        "                                         [ 0.4032,  0.7737,  0.9351, -0.5245,  0.0783],\n",
        "                                         [-1.2932, -0.9885, -1.1850, -0.7403,  0.1739],\n",
        "                                         [-0.5471,  0.5017, -1.0571,  1.7574, -0.0911],\n",
        "                                         [ 0.6944, -1.2772,  0.7473, -1.0983,  1.1462]]],\n",
        "\n",
        "\n",
        "                                       [[[-1.2563,  0.0688,  1.0405, -0.2582,  0.7333],\n",
        "                                         [ 2.0711, -0.1815,  0.8876, -0.2907,  1.1195],\n",
        "                                         [-0.3912,  0.3624,  1.0576, -0.4748, -1.4021],\n",
        "                                         [ 1.2176, -0.6160, -0.3471,  1.1689,  0.5677],\n",
        "                                         [-0.0639,  0.3765, -0.2614,  1.8267,  0.0315]],\n",
        "\n",
        "                                        [[ 1.2927,  1.0709, -0.8808,  0.8106, -0.5315],\n",
        "                                         [ 0.7614, -0.3935,  1.2451, -0.0598, -0.5887],\n",
        "                                         [-0.4089, -0.8598,  0.2478,  0.1282, -0.2745],\n",
        "                                         [-0.4139, -1.2905, -0.2625, -2.0453,  1.8941],\n",
        "                                         [-0.2400, -1.2830, -0.3503, -0.8536, -0.5927]],\n",
        "\n",
        "                                        [[ 0.8200,  1.8860, -0.5216, -0.9590, -0.9760],\n",
        "                                         [-1.5796,  2.2379, -0.5714, -1.5612,  1.4035],\n",
        "                                         [-0.6434, -1.2257,  0.1408,  0.3781, -2.2344],\n",
        "                                         [ 0.4963,  0.2431,  0.6835,  0.0047,  1.3374],\n",
        "                                         [-1.5899,  2.5382,  0.9503,  1.9080,  1.8315]],\n",
        "\n",
        "                                        [[ 0.5853,  1.9343, -0.7472,  2.1774, -2.1895],\n",
        "                                         [-0.6187, -0.2870,  1.2485,  2.4069, -0.2632],\n",
        "                                         [-1.6047, -0.3379,  0.5372,  1.7098,  1.6220],\n",
        "                                         [ 0.5255,  0.2564, -1.8615,  1.5519, -0.5655],\n",
        "                                         [-0.9452, -1.1828, -1.8192,  1.1349,  0.9806]],\n",
        "\n",
        "                                        [[-1.8198,  0.5455,  1.1761,  1.3070, -0.4654],\n",
        "                                         [ 1.2673,  0.2608,  0.8385, -1.0407, -0.6288],\n",
        "                                         [-0.3860,  1.3343,  1.3084,  0.5794,  0.4639],\n",
        "                                         [ 0.4750, -0.9006, -1.5002,  0.8689, -0.0379],\n",
        "                                         [ 0.2891,  0.0195, -0.0503, -0.3235,  1.5407]]]]], requires_grad=True)\n",
        "\n",
        "\n",
        "revz = torch.nn.functional.avg_pool3d(revx,2)\n",
        "revz.backward(torch.tensor([[[[[-0.5557,  0.7782],\n",
        "                               [ 1.2927,  0.9179]],\n",
        "                           \n",
        "                              [[ 0.4852,  0.6701],\n",
        "                               [ 0.7996, -0.9707]]],\n",
        "                           \n",
        "                           \n",
        "                             [[[ 1.0630, -0.8899],\n",
        "                               [ 0.8771,  0.0433]],\n",
        "                           \n",
        "                              [[ 0.3975,  0.0060],\n",
        "                               [-0.7735,  1.2806]]]]]))\n",
        "revx.grad\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEbgqe3dKoMo"
      },
      "source": [
        "# Investigate GLIB and GLIBCXX dependencies available on this system\n",
        "!ldd --version\n",
        "!/sbin/ldconfig -p | grep stdc++\n",
        "!strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep LIBCXX\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPezNW6wwqlP"
      },
      "source": [
        "## Install .NET SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPwCZKr-dAqp",
        "outputId": "c882f364-f593-45fd-f539-d33d2626e690"
      },
      "source": [
        "# Install dotnet\n",
        "!wget https://packages.microsoft.com/config/ubuntu/18.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb && sudo dpkg -i packages-microsoft-prod.deb && sudo apt-get update && sudo apt-get install -y apt-transport-https && sudo apt-get update && sudo apt-get install -y dotnet-sdk-5.0\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-25 20:35:16--  https://packages.microsoft.com/config/ubuntu/18.04/packages-microsoft-prod.deb\n",
            "Resolving packages.microsoft.com (packages.microsoft.com)... 13.75.64.135\n",
            "Connecting to packages.microsoft.com (packages.microsoft.com)|13.75.64.135|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3132 (3.1K) [application/octet-stream]\n",
            "Saving to: ‘packages-microsoft-prod.deb’\n",
            "\n",
            "\r          packages-   0%[                    ]       0  --.-KB/s               \rpackages-microsoft- 100%[===================>]   3.06K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-03-25 20:35:16 (142 MB/s) - ‘packages-microsoft-prod.deb’ saved [3132/3132]\n",
            "\n",
            "(Reading database ... 164248 files and directories currently installed.)\n",
            "Preparing to unpack packages-microsoft-prod.deb ...\n",
            "Unpacking packages-microsoft-prod (1.0-ubuntu18.04.2) over (1.0-ubuntu18.04.2) ...\n",
            "Setting up packages-microsoft-prod (1.0-ubuntu18.04.2) ...\n",
            "Hit:1 https://packages.microsoft.com/ubuntu/18.04/prod bionic InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:12 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,170 kB]\n",
            "Hit:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,475 kB]\n",
            "Fetched 4,897 kB in 4s (1,245 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "apt-transport-https is already the newest version (1.6.12ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 63 not upgraded.\n",
            "Hit:1 https://packages.microsoft.com/ubuntu/18.04/prod bionic InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "dotnet-sdk-5.0 is already the newest version (5.0.201-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 63 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0iT-SYGdHgP",
        "outputId": "ac754b69-48a2-452a-96b3-b8af9bab43e3"
      },
      "source": [
        "!dotnet --version"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?1h\u001b=5.0.201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ-byfcCwmf6"
      },
      "source": [
        "## Restore packages (libtorch-cpu)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxdQUMUDXL6U",
        "outputId": "be9aef05-4281-4376-919f-26f705457948"
      },
      "source": [
        "# Restore packages (libtorch-cpu)\n",
        "!echo \"printfn \\\"phase0\\\"\" > foo.fsx\n",
        "!echo \"#r \\\"nuget: TorchSharp, 0.91.52515\\\"\" >> foo.fsx\n",
        "!echo \"#r \\\"nuget: libtorch-cpu, 1.8.0.7\\\"\" >> foo.fsx\n",
        "!echo \"printfn \\\"done\\\"\" >> foo.fsx\n",
        "!cat foo.fsx\n",
        "!dotnet fsi foo.fsx\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "printfn \"phase0\"\n",
            "#r \"nuget: TorchSharp, 0.91.52515\"\n",
            "#r \"nuget: libtorch-cpu, 1.8.0.7\"\n",
            "printfn \"done\"\n",
            "\u001b[?1h\u001b=\u001b[?1h\u001b=\u001b[6n\u001b[6n\u001b[1;1Hphase0\n",
            "\u001b[?1h\u001b=done\n",
            "\u001b[?1h\u001b="
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An4M6BSCXm0k"
      },
      "source": [
        "# Look around packages and dependencies  (libtorch-cpu)\n",
        "! /lib/x86_64-linux-gnu/libc.so.6 --version\n",
        "!ls /root/.nuget/packages/libtorch-cpu/1.8.0.7/runtimes/linux-x64/native\n",
        "!ls /root/.nuget/packages/torchsharp/0.91.52515/runtimes/linux-x64/native/\n",
        "!echo LD_LIBRARY_PATH=$LD_LIBRARY_PATH\n",
        "!ldd --version\n",
        "!ldd  /root/.nuget/packages/torchsharp/0.91.52515/runtimes/linux-x64/native/libLibTorchSharp.so\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC237CqodbPX"
      },
      "source": [
        "# Run some code with workaround  (libtorch-cpu)\n",
        "!echo \"printfn \\\"phase0\\\"\" > foo.fsx\n",
        "!echo \"#r \\\"nuget: TorchSharp, 0.91.52515\\\"\" >> foo.fsx\n",
        "!echo \"#r \\\"nuget: libtorch-cpu, 1.8.0.7\\\"\" >> foo.fsx\n",
        "!echo \"printfn \\\"phase1\\\"\" >> foo.fsx\n",
        "!echo \"open System.Runtime.InteropServices\" >> foo.fsx\n",
        "!echo \"NativeLibrary.Load(\\\"/root/.nuget/packages/libtorch-cpu/1.8.0.7/runtimes/linux-x64/native/libtorch.so\\\") |> printfn \\\"%A\\\"\" >> foo.fsx\n",
        "!echo \"printfn \\\"phase2\\\"\" >> foo.fsx\n",
        "!echo \"TorchSharp.Torch.IsCudaAvailable() |> printfn \\\"%A\\\"\" >> foo.fsx\n",
        "!cat foo.fsx\n",
        "!dotnet fsi foo.fsx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgOKh9pWwxUo"
      },
      "source": [
        "## Restore packages (libtorch-cuda)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy2WYgMS5iWy",
        "outputId": "49b23ae7-a91d-4819-82a2-620627f18160"
      },
      "source": [
        "# Restore packages (libtorch-cuda)\n",
        "!echo \"printfn \\\"phase0\\\"\" > foo.fsx\n",
        "!echo \"#i \\\"nuget: https://donsyme.pkgs.visualstudio.com/TorchSharp/_packaging/packages2%40Local/nuget/v3/index.json\\\"\" >> foo.fsx\n",
        "!echo \"#r \\\"nuget: TorchSharp, 0.91.52515\\\";;\" >> foo.fsx\n",
        "!echo \"#r \\\"nuget: libtorch-cuda-11.1-linux-x64, 1.8.0.7\\\";;\" >> foo.fsx\n",
        "!echo \"printfn \\\"done\\\"\" >> foo.fsx\n",
        "!cat foo.fsx\n",
        "!echo \"-------\"\n",
        "!dotnet fsi foo.fsx\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "printfn \"phase0\"\n",
            "#i \"nuget: https://donsyme.pkgs.visualstudio.com/TorchSharp/_packaging/packages2%40Local/nuget/v3/index.json\"\n",
            "#r \"nuget: TorchSharp, 0.91.52514\";;\n",
            "#r \"nuget: libtorch-cuda-11.1-linux-x64, 1.8.0.7\";;\n",
            "printfn \"done\"\n",
            "-------\n",
            "\u001b[?1h\u001b=\u001b[?1h\u001b=\u001b[6n\u001b[6n\u001b[1;1Hphase0\n",
            "\u001b[?1h\u001b=/tmp/nuget/6736--cad1ba0d-9d5f-4476-bde5-9ced35a74c50/Project.fsproj : warning NU1603: Project depends on TorchSharp (>= 0.91.52514) but TorchSharp 0.91.52514 was not found. An approximate best match of TorchSharp 0.91.52515 was resolved.\n",
            "/tmp/nuget/6736--cad1ba0d-9d5f-4476-bde5-9ced35a74c50/Project.fsproj : warning NU1603: Project depends on TorchSharp (>= 0.91.52514) but TorchSharp 0.91.52514 was not found. An approximate best match of TorchSharp 0.91.52515 was resolved.\n",
            "\u001b[?1h\u001b=/tmp/nuget/6736--cad1ba0d-9d5f-4476-bde5-9ced35a74c50/Project.fsproj : warning NU1603: Project depends on TorchSharp (>= 0.91.52514) but TorchSharp 0.91.52514 was not found. An approximate best match of TorchSharp 0.91.52515 was resolved.\n",
            "/tmp/nuget/6736--cad1ba0d-9d5f-4476-bde5-9ced35a74c50/Project.fsproj : warning NU1603: Project depends on TorchSharp (>= 0.91.52514) but TorchSharp 0.91.52514 was not found. An approximate best match of TorchSharp 0.91.52515 was resolved.\n",
            "done\n",
            "\u001b[?1h\u001b="
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE5nMxloGiYi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXNaxxL45qyZ",
        "outputId": "cf547410-1e6c-424c-d257-9792ff1313dd"
      },
      "source": [
        "# Look around packages and dependencies  (libtorch-cuda)\n",
        "! /lib/x86_64-linux-gnu/libc.so.6 --version\n",
        "!ls /root/.nuget/packages/libtorch-cuda-11.1-linux-x64/1.8.0.7/\n",
        "!echo LD_LIBRARY_PATH=$LD_LIBRARY_PATH\n",
        "!ldd --version\n",
        "!ls /root/.nuget/packages/torchsharp/0.91.52515/runtimes/linux-x64/native/\n",
        "#!ldd  /root/.nuget/packages/torchsharp/0.91.52515/runtimes/linux-x64/native/libLibTorchSharp.so\n",
        "!ls /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/\n",
        "!ldd /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libLibTorchSharp.so"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "buildTransitive\n",
            "lib\n",
            "libtorch-cuda-11.1-linux-x64.1.8.0.7.nupkg\n",
            "libtorch-cuda-11.1-linux-x64.1.8.0.7.nupkg.sha512\n",
            "libtorch-cuda-11.1-linux-x64.nuspec\n",
            "LICENSE-LIBTORCH.txt\n",
            "LD_LIBRARY_PATH=/usr/lib64-nvidia\n",
            "ldd (Ubuntu GLIBC 2.27-3ubuntu1.2) 2.27\n",
            "Copyright (C) 2018 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "Written by Roland McGrath and Ulrich Drepper.\n",
            "libLibTorchSharp.so\n",
            "ls: cannot access '/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/': No such file or directory\n",
            "ldd: /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libLibTorchSharp.so: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EfYdLMud-Ky",
        "outputId": "ac4ec57a-472d-4de7-ebca-9552e8b17f6c"
      },
      "source": [
        "# Run some F# script code triggering the dynamic load (maybe with workaround)\n",
        "!echo \"printfn \\\"phase0\\\"\" > foo.fsx\n",
        "!echo \"#r \\\"nuget: TorchSharp, 0.91.52515\\\"\" >> foo.fsx\n",
        "!echo \"#r \\\"nuget: libtorch-cuda-11.1-linux-x64, 1.8.0.7\\\"\" >> foo.fsx\n",
        "!echo \"printfn \\\"phase2\\\"\" >> foo.fsx\n",
        "!echo \"TorchSharp.Torch.IsCudaAvailable() |> printfn \\\"%A\\\"\" >> foo.fsx\n",
        "!cat foo.fsx\n",
        "!dotnet fsi foo.fsx"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "printfn \"phase0\"\n",
            "#r \"nuget: TorchSharp, 0.91.52515\"\n",
            "#r \"nuget: libtorch-cuda-11.1-linux-x64, 1.8.0.7\"\n",
            "printfn \"phase2\"\n",
            "TorchSharp.Torch.IsCudaAvailable() |> printfn \"%A\"\n",
            "\u001b[?1h\u001b=\u001b[?1h\u001b=\u001b[6n\u001b[6n\u001b[1;1Hphase0\n",
            "\u001b[?1h\u001b=phase2\n",
            "TorchSharp: LoadNativeBackend: Initialising native backend\n",
            "TorchSharp: LoadNativeBackend: Try loading torch_cuda native component\n",
            "TorchSharp: LoadNativeBackend: Loading LibTorchSharp\n",
            "TorchSharp: LoadNativeBackend: Loaded LibTorchSharp, ok = False\n",
            "TorchSharp: LoadNativeBackend: Native backend not found in application. Trying dynamic load for .NET/F# Interactive...\n",
            "TorchSharp: LoadNativeBackend: Consolidating native libtorch-cuda-11.1-linux-x64-* binaries to /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1...\n",
            "CopyNativeComponentsIntoSingleDirectory: packagesDir = /root/.nuget/packages\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libfbjni.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libfbjni.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libnvrtc-builtins.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libnvrtc-builtins.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libtorch.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libtorch.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libgomp-7c85b1e2.so.1 --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libgomp-7c85b1e2.so.1\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libcudart-6d56b25a.so.11.0 --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libcudart-6d56b25a.so.11.0\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libcaffe2_detectron_ops_gpu.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libcaffe2_detectron_ops_gpu.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libcaffe2_module_test_dynamic.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libcaffe2_module_test_dynamic.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libjitbackend_test.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libjitbackend_test.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libcaffe2_observers.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libcaffe2_observers.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libtorch_cpu.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libtorch_cpu.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libtensorpipe_agent.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libtensorpipe_agent.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libshm.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libshm.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libnvToolsExt-24de1d56.so.1 --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libnvToolsExt-24de1d56.so.1\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libtorch_python.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libtorch_python.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libpytorch_jni.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libpytorch_jni.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libc10.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libc10.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libnvrtc-3a20f2b6.so.11.1 --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libnvrtc-3a20f2b6.so.11.1\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libc10_cuda.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libc10_cuda.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libtorchbind_test.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libtorchbind_test.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libtorch_global_deps.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libtorch_global_deps.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libc10d_cuda_test.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libc10d_cuda_test.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libprocess_group_agent.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libprocess_group_agent.so\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part1/1.8.0.7/runtimes/linux-x64/native/libcaffe2_nvrtc.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libcaffe2_nvrtc.so\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment1, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment1/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment2, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment2/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-primary, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-primary/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-primary/1.8.0.7/runtimes/linux-x64/native/libtorch_cuda_cpp.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libtorch_cuda_cpp.so\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment3, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment3/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part3-primary, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part3-primary/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part3-primary/1.8.0.7/runtimes/linux-x64/native/libtorch_cuda_cu.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libtorch_cuda_cu.so\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part3-fragment1, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part3-fragment1/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part3-fragment2, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part3-fragment2/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment6, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment6/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part4, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part4/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "Copy /root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part4/1.8.0.7/runtimes/linux-x64/native/libtorch_cuda.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libtorch_cuda.so\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment5, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment5/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment7, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment7/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part3-fragment3, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part3-fragment3/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment4, natives=/root/.nuget/packages/libtorch-cuda-11.1-linux-x64-part2-fragment4/1.8.0.7/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "TorchSharp: LoadNativeBackend: Consolidating native LibTorchSharp binaries to /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1...\n",
            "CopyNativeComponentsIntoSingleDirectory: packagesDir = /root/.nuget/packages\n",
            "CopyNativeComponentsIntoSingleDirectory: package=/root/.nuget/packages/torchsharp, natives=/root/.nuget/packages/torchsharp/0.91.52515/runtimes/linux-x64/native, target=/root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1\n",
            "Copy /root/.nuget/packages/torchsharp/0.91.52515/runtimes/linux-x64/native/libLibTorchSharp.so --> /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libLibTorchSharp.so\n",
            "TorchSharp: LoadNativeBackend: Trying to load /root/.nuget/packages/torchsharp/0.91.52515/lib/netcoreapp3.1/cuda-11.1/libLibTorchSharp.so...\n",
            "true\n",
            "\u001b[?1h\u001b="
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2Pr8mXOw3cZ"
      },
      "source": [
        "### Setup colab Fast AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSve1ct-VUkC"
      },
      "source": [
        "  !curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJP73vJwoGh4"
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxbay_8zUvvE"
      },
      "source": [
        "# Welcome to Jupyter Notebooks!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yagamv_bYo9W"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'fastai-v3/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyk566qdtfS"
      },
      "source": [
        "  !ls /content/models\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLWbHqUPfqqZ"
      },
      "source": [
        "# load an example dataset\n",
        "from vega_datasets import data\n",
        "cars = data.cars()\n",
        "\n",
        "# plot the dataset, referencing dataframe column names\n",
        "import altair as alt\n",
        "alt.Chart(cars).mark_bar().encode(\n",
        "  x=alt.X('Miles_per_Gallon', bin=True),\n",
        "  y='count()',\n",
        "  color='Origin'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gajqtorOftfj"
      },
      "source": [
        "from vega_datasets import data\n",
        "stocks = data.stocks()\n",
        "\n",
        "import altair as alt\n",
        "alt.Chart(stocks).mark_line().encode(\n",
        "  x='date:T',\n",
        "  y='price',\n",
        "  color='symbol'\n",
        ").interactive(bind_y=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDjpwcglfw7-"
      },
      "source": [
        "# load an example dataset\n",
        "from vega_datasets import data\n",
        "cars = data.cars()\n",
        "\n",
        "import altair as alt\n",
        "\n",
        "points = alt.Chart(cars).mark_point().encode(\n",
        "  x='Year:T',\n",
        "  y='Miles_per_Gallon',\n",
        "  color='Origin'\n",
        ").properties(\n",
        "  width=800\n",
        ")\n",
        "\n",
        "lines = alt.Chart(cars).mark_line().encode(\n",
        "  x='Year:T',\n",
        "  y='mean(Miles_per_Gallon)',\n",
        "  color='Origin'\n",
        ").properties(\n",
        "  width=800\n",
        ").interactive(bind_y=False)\n",
        "              \n",
        "points + lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpSbsOWIf19Q"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVxtLBF6gGq4"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDwf49jugGqk"
      },
      "source": [
        "!curl -o logo.png https://colab.research.google.com/img/colab_favicon_256px.png\n",
        "import cv2\n",
        "img = cv2.imread('logo.png', cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxQsXK4Sf182"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = '[your Cloud Platform project ID]'\n",
        "sample_count = 2000\n",
        "row_count = pd.io.gbq.read_gbq('''\n",
        "  SELECT \n",
        "    COUNT(*) as total\n",
        "  FROM [bigquery-public-data:samples.gsod]''', project_id=project_id, verbose=False).total[0]\n",
        "df = pd.io.gbq.read_gbq('''\n",
        "  SELECT\n",
        "    *\n",
        "  FROM\n",
        "    [bigquery-public-data:samples.gsod]\n",
        "  WHERE RAND() < %d/%d\n",
        "''' % (sample_count, row_count), project_id=project_id, verbose=False)\n",
        "print('Full dataset has %d rows' % row_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edkUHaGEf18g"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zntv5Q3gSuE"
      },
      "source": [
        "%%html\n",
        "<link rel=\"stylesheet\" href=\"/nbextensions/google.colab/tabbar.css\">\n",
        "<div class='goog-tab'>\n",
        "  Some content\n",
        "</div>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzJubcoqgSte"
      },
      "source": [
        "import portpicker\n",
        "import threading\n",
        "import socket\n",
        "import IPython\n",
        "\n",
        "from six.moves import socketserver\n",
        "from six.moves import SimpleHTTPServer\n",
        "\n",
        "class V6Server(socketserver.TCPServer):\n",
        "  address_family = socket.AF_INET6\n",
        "\n",
        "class Handler(SimpleHTTPServer.SimpleHTTPRequestHandler):\n",
        "  def do_GET(self):\n",
        "    self.send_response(200)\n",
        "    # If the response should not be cached in the notebook for\n",
        "    # offline access:\n",
        "    # self.send_header('x-colab-notebook-cache-control', 'no-cache')\n",
        "    self.end_headers()\n",
        "    self.wfile.write(b'''\n",
        "      document.querySelector('#output-area').appendChild(document.createTextNode('Script result!'));\n",
        "    ''')\n",
        "\n",
        "port = portpicker.pick_unused_port()\n",
        "\n",
        "def server_entry():\n",
        "    httpd = V6Server(('::', port), Handler)\n",
        "    # Handle a single request then exit the thread.\n",
        "    httpd.serve_forever()\n",
        "\n",
        "thread = threading.Thread(target=server_entry)\n",
        "thread.start()\n",
        "\n",
        "# Display some HTML referencing the resource.\n",
        "display(IPython.display.HTML('<script src=\"https://localhost:{port}/\"></script>'.format(port=port)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvQvNDwIgfdY"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = '[your Cloud Platform project ID]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMVcS2AVgf8Y"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = '[your Cloud Platform project ID]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSEvTRYqggUH"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = '[your Cloud Platform project ID]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTNn8mTGg48O"
      },
      "source": [
        "%load_ext google.colab.data_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrXoETl1g475"
      },
      "source": [
        "from vega_datasets import data\n",
        "data.cars()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88BD5tC1g47j"
      },
      "source": [
        "%unload_ext google.colab.data_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEulM2Xyg47M"
      },
      "source": [
        "data.cars()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg6vTKr0ggTv"
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')\n",
        "\n",
        "# Generate a random bucket name to which we'll upload the file.\n",
        "import uuid\n",
        "bucket_name = 'colab-sample-bucket' + str(uuid.uuid1())\n",
        "\n",
        "body = {\n",
        "  'name': bucket_name,\n",
        "  # For a full list of locations, see:\n",
        "  # https://cloud.google.com/storage/docs/bucket-locations\n",
        "  'location': 'us',\n",
        "}\n",
        "gcs_service.buckets().insert(project=project_id, body=body).execute()\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNKZYrwFggTV"
      },
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload('/tmp/to_upload.txt', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket=bucket_name, \n",
        "                                       name='to_upload.txt',\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L19I3w6Jgf7-"
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')\n",
        "\n",
        "# Generate a random bucket name to which we'll upload the file.\n",
        "import uuid\n",
        "bucket_name = 'colab-sample-bucket' + str(uuid.uuid1())\n",
        "\n",
        "body = {\n",
        "  'name': bucket_name,\n",
        "  # For a full list of locations, see:\n",
        "  # https://cloud.google.com/storage/docs/bucket-locations\n",
        "  'location': 'us',\n",
        "}\n",
        "gcs_service.buckets().insert(project=project_id, body=body).execute()\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyA7zlsOgf7l"
      },
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload('/tmp/to_upload.txt', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket=bucket_name, \n",
        "                                       name='to_upload.txt',\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qeUvFNZgfc-"
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')\n",
        "\n",
        "# Generate a random bucket name to which we'll upload the file.\n",
        "import uuid\n",
        "bucket_name = 'colab-sample-bucket' + str(uuid.uuid1())\n",
        "\n",
        "body = {\n",
        "  'name': bucket_name,\n",
        "  # For a full list of locations, see:\n",
        "  # https://cloud.google.com/storage/docs/bucket-locations\n",
        "  'location': 'us',\n",
        "}\n",
        "gcs_service.buckets().insert(project=project_id, body=body).execute()\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RWm1EFogfck"
      },
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload('/tmp/to_upload.txt', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket=bucket_name, \n",
        "                                       name='to_upload.txt',\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')\n",
        "print('https://console.cloud.google.com/storage/browser?project={}'.format(project_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Kr8UrlUvvE"
      },
      "source": [
        "If you want to learn how to use this tool you've come to the right place. This article will teach you all you need to know to use Jupyter Notebooks effectively. You only need to go through Section 1 to learn the basics and you can go into Section 2 if you want to further increase your productivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dc2x94vUvvF"
      },
      "source": [
        "You might be reading this tutorial in a web page (maybe Github or the course's webpage). We strongly suggest to read this tutorial in a (yes, you guessed it) Jupyter Notebook. This way you will be able to actually *try* the different commands we will introduce here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjlf5ZxFUvvH"
      },
      "source": [
        "## Section 1: Need to Know"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEXeK1lbUvvI"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coQeFoPEUvvK"
      },
      "source": [
        "Let's build up from the basics, what is a Jupyter Notebook? Well, you are reading one. It is a document made of cells. You can write like I am writing now (markdown cells) or you can perform calculations in Python (code cells) and run them like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwX0sbr8UvvL"
      },
      "source": [
        "1+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBZxP75mUvvR"
      },
      "source": [
        "Cool huh? This combination of prose and code makes Jupyter Notebook ideal for experimentation: we can see the rationale for each experiment, the code and the results in one comprehensive document. In fast.ai, each lesson is documented in a notebook and you can later use that notebook to experiment yourself. \n",
        "\n",
        "Other renowned institutions in academy and industry use Jupyter Notebook: Google, Microsoft, IBM, Bloomberg, Berkeley and NASA among others. Even Nobel-winning economists [use Jupyter Notebooks](https://paulromer.net/jupyter-mathematica-and-the-future-of-the-research-paper/)  for their experiments and some suggest that Jupyter Notebooks will be the [new format for research papers](https://www.theatlantic.com/science/archive/2018/04/the-scientific-paper-is-obsolete/556676/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuz9GCDoUvvS"
      },
      "source": [
        "### Writing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whqOuMOfUvvT"
      },
      "source": [
        "A type of cell in which you can write like this is called _Markdown_. [_Markdown_](https://en.wikipedia.org/wiki/Markdown) is a very popular markup language. To specify that a cell is _Markdown_ you need to click in the drop-down menu in the toolbar and select _Markdown_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gak_LizcUvvU"
      },
      "source": [
        "Click on the the '+' button on the left and select _Markdown_ from the toolbar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H7kDNNSUvvU"
      },
      "source": [
        "Now you can type your first _Markdown_ cell. Write 'My first markdown cell' and press run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeiVRU33UvvV"
      },
      "source": [
        "![add](https://github.com/fastai/course-v3/blob/master/nbs/dl1/images/notebook_tutorial/add.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shwrUy60UvvV"
      },
      "source": [
        "You should see something like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hNFakNTUvvW"
      },
      "source": [
        "My first markdown cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0Swm2JsUvvX"
      },
      "source": [
        "Now try making your first _Code_ cell: follow the same steps as before but don't change the cell type (when you add a cell its default type is _Code_). Type something like 3/2. You should see '1.5' as output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d8urTSxUvvY"
      },
      "source": [
        "3/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6poJ2d7Uvva"
      },
      "source": [
        "### Modes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNZIer_RUvva"
      },
      "source": [
        "If you made a mistake in your *Markdown* cell and you have already ran it, you will notice that you cannot edit it just by clicking on it. This is because you are in **Command Mode**. Jupyter Notebooks have two distinct modes:\n",
        "\n",
        "1. **Edit Mode**: Allows you to edit a cell's content.\n",
        "\n",
        "2. **Command Mode**: Allows you to edit the notebook as a whole and use keyboard shortcuts but not edit a cell's content. \n",
        "\n",
        "You can toggle between these two by either pressing <kbd>ESC</kbd> and <kbd>Enter</kbd> or clicking outside a cell or inside it (you need to double click if its a Markdown cell). You can always know which mode you're on since the current cell has a green border if in **Edit Mode** and a blue border in **Command Mode**. Try it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXkraHEyUvvb"
      },
      "source": [
        "### Other Important Considerations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kIVtRTpUvvc"
      },
      "source": [
        "1. Your notebook is autosaved every 120 seconds. If you want to manually save it you can just press the save button on the upper left corner or press <kbd>s</kbd> in **Command Mode**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMZlLnagUvve"
      },
      "source": [
        "![Save](https://github.com/fastai/course-v3/blob/master/nbs/dl1/images/notebook_tutorial/save.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gMYB201Uvvf"
      },
      "source": [
        "2. To know if your kernel is computing or not you can check the dot in your upper right corner. If the dot is full, it means that the kernel is working. If not, it is idle. You can place the mouse on it and see the state of the kernel be displayed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1438X21Uvvf"
      },
      "source": [
        "![Busy](https://github.com/fastai/course-v3/blob/master/nbs/dl1/images/notebook_tutorial/busy.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX-DLFYhUvvg"
      },
      "source": [
        "3. There are a couple of shortcuts you must know about which we use **all** the time (always in **Command Mode**). These are:\n",
        "\n",
        "<kbd>Shift</kbd>+<kbd>Enter</kbd>: Runs the code or markdown on a cell\n",
        "\n",
        "<kbd>Up Arrow</kbd>+<kbd>Down Arrow</kbd>: Toggle across cells\n",
        "\n",
        "<kbd>b</kbd>: Create new cell\n",
        "\n",
        "<kbd>0</kbd>+<kbd>0</kbd>: Reset Kernel\n",
        "\n",
        "You can find more shortcuts in the Shortcuts section below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1IJxLWHUvvh"
      },
      "source": [
        "4. You may need to use a terminal in a Jupyter Notebook environment (for example to git pull on a repository). That is very easy to do, just press 'New' in your Home directory and 'Terminal'. Don't know how to use the Terminal? We made a tutorial for that as well. You can find it [here](https://course.fast.ai/terminal_tutorial.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-5jC_P6Uvvh"
      },
      "source": [
        "![Terminal](https://github.com/fastai/course-v3/blob/master/nbs/dl1/images/notebook_tutorial/terminal.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EUv0X3RUvvi"
      },
      "source": [
        "That's it. This is all you need to know to use Jupyter Notebooks. That said, we have more tips and tricks below ↓↓↓"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52BgdvMhUvvi"
      },
      "source": [
        "## Section 2: Going deeper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hide_input": false,
        "id": "4AknCJ3ZUvvj"
      },
      "source": [
        "### Markdown formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5ryOAAYUvvk"
      },
      "source": [
        "#### Italics, Bold, Strikethrough, Inline, Blockquotes and Links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHZ0-lDXUvvl"
      },
      "source": [
        "The five most important concepts to format your code appropriately when using markdown are:\n",
        "    \n",
        "1. *Italics*: Surround your text with '\\_' or '\\*'\n",
        "2. **Bold**: Surround your text with '\\__' or '\\**'\n",
        "3. `inline`: Surround your text with '\\`'\n",
        "4.  > blockquote: Place '\\>' before your text.\n",
        "5.  [Links](https://course.fast.ai/): Surround the text you want to link with '\\[\\]' and place the link adjacent to the text, surrounded with '()'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_AcJ1aFUvvm"
      },
      "source": [
        "#### Headings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbfzk_F5Uvvn"
      },
      "source": [
        "Notice that including a hashtag before the text in a markdown cell makes the text a heading. The number of hashtags you include will determine the priority of the header ('#' is level one, '##' is level two, '###' is level three and '####' is level four). We will add three new cells with the '+' button on the left to see how every level of heading looks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OseIwlxkUvvo"
      },
      "source": [
        "Double click on some headings and find out what level they are!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8Y-LL6pUvvo"
      },
      "source": [
        "#### Lists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlw32r8BUvvp"
      },
      "source": [
        "There are three types of lists in markdown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nOOce-MUvvp"
      },
      "source": [
        "Ordered list:\n",
        "\n",
        "1. Step 1\n",
        "    2. Step 1B\n",
        "3. Step 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOZ663xdUvvq"
      },
      "source": [
        "Unordered list\n",
        "\n",
        "* learning rate\n",
        "* cycle length\n",
        "* weight decay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxKKqbS2Uvvq"
      },
      "source": [
        "Task list\n",
        "\n",
        "- [x] Learn Jupyter Notebooks\n",
        "    - [x] Writing\n",
        "    - [x] Modes\n",
        "    - [x] Other Considerations\n",
        "- [ ] Change the world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RvMDy7eUvvr"
      },
      "source": [
        "Double click on each to see how they are built! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iXe4caCUvvr"
      },
      "source": [
        "### Code Capabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGpyNJpsUvvs"
      },
      "source": [
        "**Code** cells are different than **Markdown** cells in that they have an output cell. This means that we can _keep_ the results of our code within the notebook and share them. Let's say we want to show a graph that explains the result of an experiment. We can just run the necessary cells and save the notebook. The output will be there when we open it again! Try it out by running the next four cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SWKZ4b4Uvvs"
      },
      "source": [
        "# Import necessary libraries\n",
        "from fastai.vision import * \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_urhGcSxUvvu"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q-GOT83Uvvv"
      },
      "source": [
        "a = 1\n",
        "b = a + 1\n",
        "c = b + a + 1\n",
        "d = c + b + a + 1\n",
        "a, b, c ,d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrdkNEJMUvvx"
      },
      "source": [
        "plt.plot([a,b,c,d])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZAwueXzUvvz"
      },
      "source": [
        "We can also print images while experimenting. I am watching you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIW_aZgRUvvz"
      },
      "source": [
        "Image.open('images/notebook_tutorial/cat_example.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj350yzxUvv1"
      },
      "source": [
        "### Running the app locally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUC15n3AUvv2"
      },
      "source": [
        "You may be running Jupyter Notebook from an interactive coding environment like Gradient, Sagemaker or Salamander. You can also run a Jupyter Notebook server from your local computer. What's more, if you have installed Anaconda you don't even need to install Jupyter (if not, just `pip install jupyter`).\n",
        "\n",
        "You just need to run `jupyter notebook` in your terminal. Remember to run it from a folder that contains all the folders/files you will want to access. You will be able to open, view and edit files located within the directory in which you run this command but not files in parent directories.\n",
        "\n",
        "If a browser tab does not open automatically once you run the command, you should CTRL+CLICK the link starting with 'https://localhost:' and this will open a new tab in your default browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woHOQxL5Uvv4"
      },
      "source": [
        "### Creating a notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psFGkR3FUvv5"
      },
      "source": [
        "Click on 'New' in the upper right corner and 'Python 3' in the drop-down list (we are going to use a [Python kernel](https://github.com/ipython/ipython) for all our experiments).\n",
        "\n",
        "![new_notebook](https://github.com/fastai/course-v3/blob/master/nbs/dl1/images/notebook_tutorial/new_notebook.png?raw=1)\n",
        "\n",
        "Note: You will sometimes hear people talking about the Notebook 'kernel'. The 'kernel' is just the Python engine that performs the computations for you. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXkMS_7XUvv6"
      },
      "source": [
        "### Shortcuts and tricks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbldGT-bUvv7"
      },
      "source": [
        "#### Command Mode Shortcuts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAUDeBmwUvv8"
      },
      "source": [
        "There are a couple of useful keyboard shortcuts in `Command Mode` that you can leverage to make Jupyter Notebook faster to use. Remember that to switch back and forth between `Command Mode` and `Edit Mode` with <kbd>Esc</kbd> and <kbd>Enter</kbd>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tANz7knWUvv9"
      },
      "source": [
        "<kbd>m</kbd>: Convert cell to Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fQ1KsQHUvv9"
      },
      "source": [
        "<kbd>y</kbd>: Convert cell to Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuzhMxSJUvv-"
      },
      "source": [
        "<kbd>D</kbd>+<kbd>D</kbd>: Delete the cell(if it's not the only cell) or delete the content of the cell and reset cell to Code(if only one cell left)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EQJWTjHUvv_"
      },
      "source": [
        "<kbd>o</kbd>: Toggle between hide or show output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJX_dHj5Uvv_"
      },
      "source": [
        "<kbd>Shift</kbd>+<kbd>Arrow up/Arrow down</kbd>: Selects multiple cells. Once you have selected them you can operate on them like a batch (run, copy, paste etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5uCiILNUvwA"
      },
      "source": [
        "<kbd>Shift</kbd>+<kbd>M</kbd>: Merge selected cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwFNvtOxUvwB"
      },
      "source": [
        "<kbd>Shift</kbd>+<kbd>Tab</kbd>: [press these two buttons at the same time, once] Tells you which parameters to pass on a function\n",
        "<kbd>Shift</kbd>+<kbd>Tab</kbd>: [press these two buttons at the same time, three times] Gives additional information on the method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2A0LypIUvwB"
      },
      "source": [
        "#### Cell Tricks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9_tLIc4UvwC"
      },
      "source": [
        "from fastai import*\n",
        "from fastai.vision import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2plXuHzUvwD"
      },
      "source": [
        "There are also some tricks that you can code into a cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziXaiQulUvwE"
      },
      "source": [
        "`?function-name`: Shows the definition and docstring for that function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hLjAyoqUvwE"
      },
      "source": [
        "?ImageDataBunch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93sUo5XFUvwG"
      },
      "source": [
        "`??function-name`: Shows the source code for that function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99e474ftUvwG"
      },
      "source": [
        "??ImageDataBunch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkxLLAnmUvwJ"
      },
      "source": [
        "`doc(function-name)`: Shows the definition, docstring **and links to the documentation** of the function\n",
        "(only works with fastai library imported)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVTDc-rFUvwK"
      },
      "source": [
        "doc(ImageDataBunch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRhQ2ZaGUvwM"
      },
      "source": [
        "#### Line Magics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuB3IPTUUvwN"
      },
      "source": [
        "Line magics are functions that you can run on cells and take as an argument the rest of the line from where they are called. You call them by placing a '%' sign before the command. The most useful ones are:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3h4hfxfUvwN"
      },
      "source": [
        "`%matplotlib inline`: This command ensures that all matplotlib plots will be plotted in the output cell within the notebook and will be kept in the notebook when saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rGZ359YUvwO"
      },
      "source": [
        "`%reload_ext autoreload`, `%autoreload 2`: Reload all modules before executing a new line. If a module is edited, it is not necessary to rerun the import commands, the modules will be reloaded automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvyvhG1UUvwP"
      },
      "source": [
        "These three commands are always called together at the beginning of every notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH-QRXCZUvwP"
      },
      "source": [
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGvlK5roUvwR"
      },
      "source": [
        "`%timeit`: Runs a line a ten thousand times and displays the average time it took to run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEwPY4lwUvwR"
      },
      "source": [
        "%timeit [i+1 for i in range(1000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N00DmCLUvwT"
      },
      "source": [
        "`%debug`: Allows to inspect a function which is showing an error using the [Python debugger](https://docs.python.org/3/library/pdb.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMKACKKJUvwT"
      },
      "source": [
        "for i in range(1000):\n",
        "    a = i+1\n",
        "    b = 'string'\n",
        "    c = b+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eitk7q2UvwV"
      },
      "source": [
        "%debug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEnylviFUvwX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}