<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <!-- 
      The DiffSharp: Automatic Differentiation Library
 parameters will be replaced with the 
      document title extracted from the <h1> element or
      file name, if there is no <h1> heading
    -->
    <title>DiffSharp: Automatic Differentiation Library
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Atılım Güneş Baydin; Barak A. Pearlmutter">
    <meta name="description" content="DiffSharp is an automatic differentiation (AD) library implemented in the F# language by Atılım Güneş Baydin and Barak A. Pearlmutter, mainly for research applications in machine learning, as part of their work at the Brain and Computation Lab, Hamilton Institute, National University of Ireland Maynooth.">

    <script src="https://code.jquery.com/jquery-1.8.0.js"></script>
    <script src="https://code.jquery.com/ui/1.8.23/jquery-ui.js"></script>
    <script src="https://netdna.bootstrapcdn.com/twitter-bootstrap/2.2.1/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link href="https://netdna.bootstrapcdn.com/twitter-bootstrap/2.2.1/css/bootstrap-combined.min.css" rel="stylesheet">
    
    <link type="text/css" rel="stylesheet" href="misc/style.css" />
    <script src="misc/tips.js" type="text/javascript"></script>
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-48900508-3', 'auto');
      ga('require', 'displayfeatures');
      ga('send', 'pageview');
    </script>
  </head>
  <body>
    <div class="container">
      <div class="masthead">
        <ul class="nav nav-pills pull-right">
          <li><a href="http://fsharp.org">fsharp.org</a></li>
        </ul>
        <h3 class="muted">DiffSharp</h3>
      </div>
      <hr />
      <div class="row">
        <div class="span9" id="main">
          <h1>DiffSharp: Automatic Differentiation Library</h1>

<p>DiffSharp is an <a href="http://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation</a> (AD) library implemented in the F# language.</p>

<p>AD allows exact and efficient calculation of derivatives, by systematically invoking the chain rule of calculus at the elementary operator level during program execution. AD is different from <a href="http://en.wikipedia.org/wiki/Numerical_differentiation">numerical differentiation</a>, which is prone to truncation and round-off errors, and <a href="http://en.wikipedia.org/wiki/Symbolic_computation">symbolic differentiation</a>, which suffers from expression swell and cannot handle algorithmic control flow.</p>

<p>Using the DiffSharp library, derivative calculations (gradients, Hessians, Jacobians, directional derivatives, and matrix-free Hessian- and Jacobian-vector products) can be incorporated with minimal change into existing algorithms. Operations can be nested to any level, meaning that you can compute exact higher-order derivatives and differentiate functions that are internally making use of differentiation. Please see the <a href="api-overview.html">API Overview</a> page for a list of available operations.</p>

<p>The library is under active development by <a href="http://www.cs.nuim.ie/~gunes/">Atılım Güneş Baydin</a> and <a href="http://bcl.hamilton.ie/~barak/">Barak A. Pearlmutter</a> mainly for research applications in machine learning, as part of their work at the <a href="http://www.bcl.hamilton.ie/">Brain and Computation Lab</a>, Hamilton Institute, National University of Ireland Maynooth.</p>

<div class="row">
    <div class="span9">
    <div class="well well-small" id="nuget" style="background-color:#F0B2B2">
        <b>As of version 0.6, DiffSharp supports nesting of AD operations.</b> This entails important changes in the library structure. Please see the <a href="https://github.com/gbaydin/DiffSharp/releases">release notes</a> to learn about the changes and how you can update your code.
    </div>
    </div>
</div>

<h2>How to Get</h2>

<p>You can install the library via NuGet. You can also download the source code or the binaries of the latest release <a href="https://github.com/gbaydin/DiffSharp/releases">on GitHub</a>.</p>

<div class="row">
    <div class="span1"></div>
    <div class="span7">
    <div class="well well-small" id="nuget">
        The DiffSharp library <a href="https://www.nuget.org/packages/diffsharp">is available on NuGet</a>. To install, run the following command in the <a href="http://docs.nuget.org/docs/start-here/using-the-package-manager-console">Package Manager Console</a>:
        <pre>PM> Install-Package DiffSharp</pre>
    </div>
    </div>
    <div class="span1"></div>
</div>

<h2>Quick Usage Example</h2>

<table class="pre"><tr><td class="lines"><pre class="fssnip">
<span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
<span class="l">17: </span>
</pre>
</td>
<td class="snippet"><pre class="fssnip">
<span class="c">// Use mixed mode nested AD</span>
<span class="k">open</span> <span onmouseout="hideTip(event, 'fs1', 1)" onmouseover="showTip(event, 'fs1', 1)" class="i">DiffSharp</span><span class="o">.</span><span onmouseout="hideTip(event, 'fs2', 2)" onmouseover="showTip(event, 'fs2', 2)" class="i">AD</span>

<span class="c">// A scalar-to-scalar function</span>
<span class="k">let</span> <span onmouseout="hideTip(event, 'fs3', 3)" onmouseover="showTip(event, 'fs3', 3)" class="f">f</span> <span onmouseout="hideTip(event, 'fs4', 4)" onmouseover="showTip(event, 'fs4', 4)" class="i">x</span> <span class="o">=</span> <span onmouseout="hideTip(event, 'fs5', 5)" onmouseover="showTip(event, 'fs5', 5)" class="f">sin</span> (<span onmouseout="hideTip(event, 'fs6', 6)" onmouseover="showTip(event, 'fs6', 6)" class="f">sqrt</span> <span onmouseout="hideTip(event, 'fs4', 7)" onmouseover="showTip(event, 'fs4', 7)" class="i">x</span>)

<span class="c">// Derivative of f</span>
<span class="k">let</span> <span onmouseout="hideTip(event, 'fs7', 8)" onmouseover="showTip(event, 'fs7', 8)" class="f">df</span> <span class="o">=</span> <span onmouseout="hideTip(event, 'fs8', 9)" onmouseover="showTip(event, 'fs8', 9)" class="f">diff</span> <span onmouseout="hideTip(event, 'fs3', 10)" onmouseover="showTip(event, 'fs3', 10)" class="f">f</span>

<span class="c">// A vector-to-scalar function</span>
<span class="k">let</span> <span onmouseout="hideTip(event, 'fs9', 11)" onmouseover="showTip(event, 'fs9', 11)" class="f">g</span> (<span onmouseout="hideTip(event, 'fs10', 12)" onmouseover="showTip(event, 'fs10', 12)" class="i">x</span><span class="o">:</span>_[]) <span class="o">=</span> <span onmouseout="hideTip(event, 'fs11', 13)" onmouseover="showTip(event, 'fs11', 13)" class="f">exp</span> (<span onmouseout="hideTip(event, 'fs10', 14)" onmouseover="showTip(event, 'fs10', 14)" class="i">x</span><span class="o">.</span>[<span class="n">0</span>] <span class="o">*</span> <span onmouseout="hideTip(event, 'fs10', 15)" onmouseover="showTip(event, 'fs10', 15)" class="i">x</span><span class="o">.</span>[<span class="n">1</span>]) <span class="o">+</span> <span onmouseout="hideTip(event, 'fs10', 16)" onmouseover="showTip(event, 'fs10', 16)" class="i">x</span><span class="o">.</span>[<span class="n">2</span>]

<span class="c">// Gradient of g</span>
<span class="k">let</span> <span onmouseout="hideTip(event, 'fs12', 17)" onmouseover="showTip(event, 'fs12', 17)" class="f">gg</span> <span class="o">=</span> <span onmouseout="hideTip(event, 'fs13', 18)" onmouseover="showTip(event, 'fs13', 18)" class="f">grad</span> <span onmouseout="hideTip(event, 'fs9', 19)" onmouseover="showTip(event, 'fs9', 19)" class="f">g</span> 

<span class="c">// Hessian of g</span>
<span class="k">let</span> <span onmouseout="hideTip(event, 'fs14', 20)" onmouseover="showTip(event, 'fs14', 20)" class="f">hg</span> <span class="o">=</span> <span onmouseout="hideTip(event, 'fs15', 21)" onmouseover="showTip(event, 'fs15', 21)" class="f">hessian</span> <span onmouseout="hideTip(event, 'fs9', 22)" onmouseover="showTip(event, 'fs9', 22)" class="f">g</span>
</pre>
</td>
</tr>
</table>

<h2>More Info and How to Cite</h2>

<p>If you are using DiffSharp and would like to cite it, please use the following information:</p>

<p><em>Atılım Güneş Baydin, Barak A. Pearlmutter, Alexey Andreyevich Radul, Jeffrey Mark Siskind (2015) Automatic differentiation and machine learning: a survey. arXiv preprint. arXiv:1502.05767</em> (<a href="http://arxiv.org/abs/1502.05767">link</a>) (<a href="misc/adml2015.bib">BibTeX</a>)</p>

<p>For a quick overview of AD and other differentiation methods, you can refer to our <a href="http://www.cs.nuim.ie/~gunes/files/AGBaydinICML2014Poster.pdf">recent poster</a> for the AutoML workshop at the International Conference on Machine Learning 2014. For in-depth material, you can check our <a href="http://www.bcl.hamilton.ie/publications/">publications page</a> and the <a href="http://www.autodiff.org/">autodiff.org</a> website.</p>

<p>If you are using DiffSharp, we would be very happy to put a link to your work on this page.</p>

<h2>Future Releases</h2>

<p>We are working on the following features:</p>

<ul>
<li>Improved Hessian calculations exploiting structure (e.g. sparsity)</li>
<li>AD via source code transformation, using code quotations</li>
<li>Compiling to GPU</li>
</ul>

          <div class="tip" id="fs1">namespace DiffSharp</div>
<div class="tip" id="fs2">namespace DiffSharp.AD</div>
<div class="tip" id="fs3">val f : x:D -&gt; D<br /><br />Full name: Index.f</div>
<div class="tip" id="fs4">val x : D</div>
<div class="tip" id="fs5">val sin : value:&#39;T -&gt; &#39;T (requires member Sin)<br /><br />Full name: Microsoft.FSharp.Core.Operators.sin</div>
<div class="tip" id="fs6">val sqrt : value:&#39;T -&gt; &#39;U (requires member Sqrt)<br /><br />Full name: Microsoft.FSharp.Core.Operators.sqrt</div>
<div class="tip" id="fs7">val df : (D -&gt; D)<br /><br />Full name: Index.df</div>
<div class="tip" id="fs8">val diff : f:(D -&gt; D) -&gt; x:D -&gt; D<br /><br />Full name: DiffSharp.AD.DiffOps.diff</div>
<div class="tip" id="fs9">val g : x:D [] -&gt; D<br /><br />Full name: Index.g</div>
<div class="tip" id="fs10">val x : D []</div>
<div class="tip" id="fs11">val exp : value:&#39;T -&gt; &#39;T (requires member Exp)<br /><br />Full name: Microsoft.FSharp.Core.Operators.exp</div>
<div class="tip" id="fs12">val gg : (D [] -&gt; D [])<br /><br />Full name: Index.gg</div>
<div class="tip" id="fs13">val grad : f:(D [] -&gt; D) -&gt; x:D [] -&gt; D []<br /><br />Full name: DiffSharp.AD.DiffOps.grad</div>
<div class="tip" id="fs14">val hg : (D [] -&gt; D [,])<br /><br />Full name: Index.hg</div>
<div class="tip" id="fs15">val hessian : f:(D [] -&gt; D) -&gt; x:D [] -&gt; D [,]<br /><br />Full name: DiffSharp.AD.DiffOps.hessian</div>
          
        </div>
        <div class="span3">
          <a href="index.html"><img src="img/diffsharp-logo.png" style="width:140px;height:140px;margin:10px 0px 0px 20px;border-style:none;"/></a>

          <ul class="nav nav-list" id="menu">
            <li class="nav-header">DiffSharp</li>
            <li class="divider"></li>
            <li><a href="index.html">Home Page</a></li>
            <li><a href="https://www.nuget.org/packages/diffsharp">Get DiffSharp via NuGet</a></li>
            <li><a href="http://github.com/gbaydin/DiffSharp">GitHub Page</a></li>
            <li><a href="http://github.com/gbaydin/DiffSharp/releases">Release Notes</a></li>

            <li class="nav-header">Getting Started</li>
            <li class="divider"></li>
            <li><a href="gettingstarted-typeinference.html">Type Inference</a></li>
            <li><a href="api-overview.html">API Overview</a></li>
            <li><a href="gettingstarted-nestedad.html">Nested AD</a></li>
            <li><a href="gettingstarted-nonnestedad.html">Non-nested AD</a></li>
            <li><a href="gettingstarted-numericaldifferentiation.html">Numerical Differentiation</a></li>
            <li><a href="gettingstarted-symbolicdifferentiation.html">Symbolic Differentiation</a></li>
            <li><a href="benchmarks.html">Benchmarks</a></li>
            <li><a href="reference/index.html">API Reference</a></li>

            <li class="nav-header">Examples</li>
            <li class="divider"></li>

            <li class="nav-header">Machine Learning</li>
            <li><a href="examples-gradientdescent.html">Gradient Descent</a></li>
            <li><a href="examples-newtonsmethod.html">Newton's Method</a></li>
            <li><a href="examples-stochasticgradientdescent.html">Stochastic Gradient Descent</a></li>
            <li><a href="examples-kmeansclustering.html">K-Means Clustering</a></li>
            <li><a href="examples-hamiltonianmontecarlo.html">Hamiltonian Monte Carlo</a></li>
            <li><a href="examples-neuralnetworks.html">Neural Networks</a></li>
            <li>Neural Turing Machines (to come)</li>
            <li>Probabilistic Programming<br>(to come)</li>

            <li class="nav-header">Dynamical Systems</li>
            <li>Stability Analysis (to come)</li>

            <li class="nav-header">Control</li>
            <li><a href="examples-inversekinematics.html">Inverse Kinematics</a></li>
            <li>Adaptive Control (to come)</li>

            <li class="nav-header">Physics</li>
            <li><a href="examples-kinematics.html">Kinematics</a></li>
            <li>Leapfrog Integration (to come)</li>
            <li><a href="examples-helmholtzenergyfunction.html">Helmholtz Energy Function</a></li>

            <li class="nav-header">Math</li>
            <li><a href="examples-lhopitalsrule.html">l'Hôpital's Rule</a></li>

            <li class="nav-header">Makers</li>
            <li class="divider"></li>
            <li><a href="http://www.cs.nuim.ie/~gunes/">Atılım Güneş Baydin</a></li>
            <li><a href="http://www.bcl.hamilton.ie/~barak/">Barak A. Pearlmutter</a></li>
            <li><a href="http://www.bcl.hamilton.ie/">Brain and Computation Lab</a></li>
          </ul>
        </div>
      </div>
    </div>
    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
    var sc_project=10059115; 
    var sc_invisible=1; 
    var sc_security="92275ee1"; 
    var scJsHost = (("https:" == document.location.protocol) ?
    "https://secure." : "http://www.");
    document.write("<sc"+"ript type='text/javascript' src='" +
    scJsHost+
    "statcounter.com/counter/counter.js'></"+"script>");
    </script>
    <noscript><div class="statcounter"><a title="web stats"
    href="http://statcounter.com/free-web-stats/"
    target="_blank"><img class="statcounter"
    src="http://c.statcounter.com/10059115/0/92275ee1/1/"
    alt="web stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide -->
  </body>
</html>
